n <- nrow(data)
salary <- function(i) data[["salary"]][i]
add_constraint(model, sum_expr(colwise(salary(i)) * x[i], i = 1:n) >= min_salary)
}
add_generic_positions_constraint <- function(model, data, constraints) {
# check position names
constraints <- parse_constraints(constraints)
unique_pos <- constraints$pos
assert_has_positions(data, constraints$pos)
# position constraint helpers
n <- nrow(data)
is_position <- function(pos) {
function(i) {
as.integer(pos == data$position[i])
}
}
# loop over every position constraint
k <- nrow(constraints)
for(ki in seq_len(k)) {
# params
pos <- constraints$pos[ki]
min_count <- constraints$min[ki]
max_count <- constraints$max[ki]
f <- is_position(pos)
# minimum constraint
model <- add_constraint(model, sum_expr(colwise(f(i)) * x[i], i = 1:n) >= min_count)
# maximum constraint
model <- add_constraint(model, sum_expr(colwise(f(i)) * x[i], i = 1:n) <= max_count)
}
# return model
model
}
#' Optimize a fantasy Model
#' @param data projected fantasy points
#' @param model optimization model
#' @param L total number of lineups
#' @param solver ROI solver to use
#' @param bans row_ids of players to exclude from all lineups
#' @param locks row_ids or players to include in all lineups
#' @param stack_sizes size of each stack
#' @param stack_teams
#' @param stack_sizes2
#' @param game_stack_sizes subset of teams to use to generate stacks. NULL will use all teams.
#' @param min_salary minimum salary to use
#' @param max_exposure max exposure for all players or a vector of exposures for each player
#' @param randomness a function that takes a vector of data and randomly perturbs it
#' @importFrom dplyr
#' @export
optimize_generic <- function(data, model, L = 5L,
solver = c("glpk", "symphony", "cbc"),
bans = NULL,
locks = NULL,
stack_sizes = NULL,
stack_teams = NULL,
stack_sizes2 = NULL,
game_stack_sizes = NULL,
min_salary = NULL,
max_exposure = 1,
randomness = NULL) {
# check inputs
if (any(is.na(data[["fpts_proj"]]))) {
stop("fpts_proj can't have NAs", call. = FALSE)
}
# add bans/locks
model <- add_player_lock_constraint(model, locks)
model <- add_player_ban_constraint(model, bans)
# add stacking
if (length(stack_sizes) > 0) {
model <- add_stack_size_constraint(model, data, stack_sizes, stack_teams)
}
# add stacking
if (length(stack_sizes2) > 0) {
model <- add_game_stack_size_constraint(model, data, stack_sizes2)
}
# add min salary
if (!is.null(min_salary)) {
model <- add_min_salary_constraint(model, data, min_salary)
}
# add exposure
n <- nrow(data)
nx <- length(max_exposure)
if (!(identical(nx, 1L) || identical(nx, n))) {
stop("exposure must be a single number or a vector with a number for each player", call. = FALSE)
}
if (any(max_exposure < 0) || any(max_exposure > 1)) {
stop("all exposure values must be between 0 and 1", call. = FALSE)
}
# if there are locked players, they need to have a max_exposure of 100%
if (identical(nx, 1L)) max_exposure <- rep(max_exposure, n)
if (!is.null(locks)) {
max_exposure[locks] <- 1
}
current_exposure <- vector("integer", n)
exposure_bans <- NULL
# copy of original data to modify for randomness
data_random <- data
# optimize
results <- vector("list", L)
solver <- match.arg(solver)
for (i in 1:L) {
# create a temporary model to hold current exposure bans
model_tmp <- add_player_ban_constraint(model, bans = exposure_bans)
# add randomness
if (is.function(randomness)) {
data_random[["fpts_proj"]] <- randomness(data_random[["fpts_proj"]])
}
# solve
result <- optimize_generic_one(data_random, model_tmp, solver)
# get results
roster <- result$roster
results[[i]] <- roster
roster_rowids <- roster$row_id
roster_ids <- roster$player_id
# add constraint to not generate same lineup again
model <- add_existing_roster_constraint(model, roster_rowids)
# add constraint to ban players from too much exposure
selected_players <- data$row_id[data$player_id %in% roster_ids]
current_exposure[selected_players] <- current_exposure[selected_players] + 1L
exposure_bans <- where(current_exposure/i > max_exposure)
}
results
}
#' Optimize fantasy lineups
#' @importFrom ompr solve_model get_solution
#' @importFrom ompr.roi with_ROI
#' @keywords internal
optimize_generic_one <- function(data, model, solver = c("glpk", "symphony", "cbc")) {
# set objective
n <- nrow(data)
fpts <- function(i) data[["fpts_proj"]][i]
model <- set_generic_objective(model, n, fpts)
# solve model
solver <- match.arg(solver)
result <- solve_model(model, with_ROI(solver = solver))
# determine if continuous or binary optimization
type <- model$variables$x$type
# extract selected
solution <- get_solution(result, x[i])
if (type == "binary") {
matches <- solution[solution[["value"]] == 1,]
matches <- matches$i
lineup <- tibble::as_tibble(data[matches, ])
} else {
lineup <- data
lineup[["x"]] <- solution[["value"]]
}
structure(
list(
result = result,
roster = lineup
),
class = "lineup"
)
}
#' "Export to csv" Draftkings Classic
#'
#' @param path path to csv file
#' @importFrom tidyverse janitor
#' @expor
read_dk <- function(path) {
df <- utils::read.csv(path, stringsAsFactors = FALSE, check.names = FALSE) %>% clean_names() %>% mutate(is_ban = 0, is_lock = 0, max_exposure = 1.0) %>% mutate(game_info = str_extract(game_info, "^[^\\s]+"))
# add fpts_proj if it doesn't exist
if (!("fpts_proj" %in% colnames(df))) {
df[["fpts_proj"]] <- df$avg_points_per_game
}
# check column headers
headers <- c("position", "name_id", "name", "id","roster_position",
"salary", "game_info","team_abbrev","avg_points_per_game", "fpts_proj", "is_ban", "is_lock", "max_exposure")
assert_has_cols(df, headers)
df <- df[headers]
# rename headers
new_headers <- trimws(tolower(headers))
new_headers <- gsub(" \\+ | ", "_", new_headers)
colnames(df) <- new_headers
# add opposing team
df <- add_dk_opp_team(df)
# trim whitespace (this also makes each column a character vector)
df[] <- lapply(df, trimws)
# fix column types
df[["id"]] <- as.character(df[["id"]])
df[["salary"]] <- as.integer(df[["salary"]])
df[["avg_points_per_game"]] <- as.double(df[["avg_points_per_game"]])
df[["fpts_proj"]] <- as.double(df[["fpts_proj"]])
# select columns for model
df_model <- df[c("id", "name", "team_abbrev", "opp_team", "location",
"position", "salary", "game_info", "avg_points_per_game", "fpts_proj", "is_ban", "is_lock", "max_exposure")]
colnames(df_model) <- c("player_id", "player", "team", "opp_team", "location",
"position", "salary", "game_info", "fpts_avg", "fpts_proj", "is_ban", "is_lock", "max_exposure")
df_model[["position"]] <- strsplit(df_model[["position"]], "/")
# expand multiple position players
df_tidy <- unnest_col(df_model, "position")
# filer FLEX and UTIL positions
df_tidy <- df_tidy[!grepl("FLEX|UTIL", df_tidy[["position"]]),]
# add row id
df_tidy <- add_row_id(df_tidy)
# tibble
tibble::as_tibble(df_tidy)
}
#' Add a row id column to the data frame
#'
#' @param df data frame
#' @keywords internal
add_row_id <- function(df) {
row.names(df) <- NULL
orig_colnames <- colnames(df)
df[["row_id"]] <- seq_len(nrow(df))
df[c("row_id", orig_colnames)]
}
#' Add opposing team
#' @keywords internal
add_dk_opp_team <- function(df) {
game_info <- unique(df[["game_info"]])
regs <- parse_locations(game_info)
away_team <- regs[,2]
home_team <- regs[,3]
teams <- data.frame(
team = c(away_team, home_team),
opp_team = c(home_team, away_team),
location = rep(home_team, 2),
stringsAsFactors = FALSE)
merge(df, teams, by.x = "team_abbrev", by.y = "team", all.x = TRUE)
}
assert_is_length_one_or_n <- function(x, n) {
stopifnot(length(x) == 1L | length(x) == n)
}
#' Assert that the dataframe has certain columns
#'
#' @param df a data frame
#' @param cols column names
#' @keywords internal
assert_has_cols <- function(df, cols) {
is_in_df <- cols %in% colnames(df)
has_all_cols <- all(is_in_df)
if (!has_all_cols) {
missing <- paste0(cols[!is_in_df], collapse = ", ")
stop(paste("missing columns", missing), call. = FALSE)
}
}
#' Make sure columns in data frame are the right type
#'
#' @param df data frame
#' @param cols column names
#' @param coltypes column types (ex. "integer", "double", "character")
#' @keywords internal
assert_coltypes <- function(df, cols, coltypes) {
are_correct <- mapply(function(d, dtype) identical(typeof(d), dtype),
df[cols], coltypes, SIMPLIFY = FALSE)
are_correct <- unlist(are_correct)
if (!all(are_correct)) {
incorrect_cols <- cols[!are_correct]
incorrect_types <- vapply(incorrect_cols, function(col) typeof(df[[col]]), character(1L))
correct_types <- coltypes[!are_correct]
incorrect_msg <- paste("\t-", incorrect_cols, "is",  incorrect_types, "but should be", correct_types, "\n")
base_msg <- "The following columns are the wrong type\n"
stop(paste(base_msg, incorrect_msg, collapse = ""), call. = FALSE)
}
}
assert_has_positions <- function(df, allowed_positions) {
positions <- unlist(strsplit(df[["position"]], "/"))
# distinct positions
positions <- sort(unique(positions))
extra_positions <- setdiff(positions, allowed_positions)
missing_positions <- setdiff(allowed_positions, positions)
if (length(extra_positions) > 0) {
extra <- paste(extra_positions, collapse = ",")
stop(paste("invalid positions:", extra), call. = FALSE)
}
if (length(missing_positions) > 0) {
missing <- paste(missing_positions, collapse = ",")
stop(paste("missing positions:", missing), call. = FALSE)
}
}
normalize_positions <- function(pos, pos_max, wildcard) {
# group by position and rank
pos_rank <- as.data.frame(pos, stringsAsFactors = FALSE)
pos_rank[["rank"]] <- stats::ave(pos, pos, FUN = function(x) rank(x, ties.method = "first"))
pos_rank[["rank"]] <- as.integer(pos_rank[["rank"]])
pos_rank[["order"]] <- seq_len(nrow(pos_rank))
# determine max rank available for each position
pos_max <- data.frame(pos = names(pos_max), max_rank = as.integer(pos_max),
stringsAsFactors = FALSE, row.names = NULL)
# merge actual rank and max rank data frames
pos_df <- merge(pos_rank, pos_max, "pos", all.x = TRUE)
# if a max rank wasn't provided then assume it is Inf
pos_df[["max_rank"]] <- with(pos_df, ifelse(is.na(max_rank), Inf, max_rank))
# make sure original order is retained
pos_df <- pos_df[order(pos_df[["order"]]),]
# assign wildcard position if actual rank exceed max_rank
pos_df[["new_pos"]] <- with(pos_df, ifelse(rank > max_rank, wildcard, pos))
pos_df[["new_pos"]]
}
normalize_lineup <- function(lineup, gamechoice = c("Classic", "Showdown"),
siteChoices = c("Draftkings", "Fanduel"),
sportChoices = c("nfl", "ncaa"),
colname = "position")   {
gamechoice <- match.arg(gamechoice)
siteChoices <- match.arg(siteChoices)
sport <- match.arg(sportChoices)
# choose normalization function
if (gamechoice == "Classic") {
if (sport == "nfl") {
f <- normalize_dk_nfl
pos_levels <- c("QB", "RB", "WR", "TE", "FLEX", "DST")
}
else if (sport == "ncaa") {
f <- normalize_dk_ncaa
pos_levels <- c("QB", "RB", "WR")
}
} else if (gamechoice == "Showdown") {
if (sport == "nfl") {
f <- normalize_sd_nfl
pos_levels <- c("CPT", "UTIL")
}
else if (sport == "ncaa") {
f <- normalize_sd_ncaa
pos_levels <- c("CPT", "UTIL")
}
}
# apply normalization
if (!is.null(f)) {
lineup[[colname]] <- f(lineup[[colname]])
}
# order by position
pos2 <- factor(lineup[[colname]], levels = pos_levels)
lineup[order(pos2),]
}
normalize_dk_nfl <- function(pos) {
stopifnot(length(pos) == 9L)
pos_max <- c("QB" = 1, "RB" = 2, "WR" = 3, "TE" = 1, "DST" = 1)
wildcard <- "FLEX"
normalize_positions(pos, pos_max, wildcard)
}
normalize_dk_ncaa <- function(pos) {
stopifnot(length(pos) == 8L)
pos_max <- c("QB" = 1, "RB" = 2, "WR" = 3)
wildcard <- "FLEX"
normalize_positions(pos, pos_max, wildcard)
}
normalize_sd_nfl <- function(pos) {
stopifnot(length(pos) == 6L)
pos_max <- c("CPT" = 1, "UTIL" = 5)
normalize_positions(pos, pos_max)
}
normalize_sd_ncaa <- function(pos) {
stopifnot(length(pos) == 6L)
pos_max <- c("CPT" = 1, "UTIL" = 5)
normalize_positions(pos, pos_max)
}
convert_lineup <- function(lineup,
gamechoice = c("Classic", "Showdown"),
siteChoices = c("Draftkings", "Fanduel"),
sportChoices = c("nfl", "ncaa"), ...) {
new_lineup <- normalize_lineup(lineup, gamechoice,siteChoices, sportChoices, ...)
player_ids <- as.list(new_lineup[["player_id"]])
x <- as.data.frame(player_ids, stringsAsFactors = FALSE)
colnames(x) <- new_lineup[["position"]]
x
}
#' Write lineups for submission
#'
#' @param lineups a normalized lineup
#' @param path local disk path
#' @param gamechoice name of DFS site
#' @param siteChoices name of DFS site
#' @param sportChoices name of sport
#' @param ... additional arguments passed to \code{\link{normalize_lineup}}
#' @export
#'
write_lineups <- function(lineups, path = NULL,
gamechoice = c("Classic", "Showdown"),
siteChoices = c("Draftkings", "Fanduel"),
sportChoices = c("nfl", "ncaa"), ...) {
converted_lineups <- lapply(lineups, convert_lineup, gamechoice,siteChoices, sportChoices, ...)
df <- do.call(rbind, converted_lineups)
if (!is.null(path)) {
utils::write.csv(df, file = path, row.names = FALSE, quote = FALSE)
}
df
}
where <- function(x) {
result <- which(x)
if (length(result) == 0) {
NULL
} else {
result
}
}
#' @export
print.lineup <- function(x, ...) {
cat("<Lineup - Value: ", x$result$objective_value, ">\n", sep = "")
print(x$roster)
invisible(x)
}
#' @keywords internal
file_type <- function(path) {
filename <- basename(path)
split <- strsplit(filename, "\\.")
vapply(split, function(x) x[2], FUN.VALUE = character(1L))
}
`%||%` <- function(x, y) {
if(is.null(x) || length(x) == 0) y else x
}
unnest_col <- function(df, colname) {
# original column order
cnames <- colnames(df)
# add dummy id
n <- nrow(df)
df[[".i"]] <- seq_len(n)
# unnest column
df_unnest <- lapply(seq_len(n), function(i) {
pos <- df[[colname]][[i]]
d <- data.frame(i, pos, stringsAsFactors = FALSE)
colnames(d) <- c(".i", colname)
d
})
df_unnest <- do.call(rbind, df_unnest)
# remove col from orig data frame
df <- df[setdiff(colnames(df), colname)]
# join back to data
df_merge <- merge(df, df_unnest, by = c(".i"))
df_merge <- df_merge[setdiff(colnames(df_merge), ".i")]
# use original column order
df_merge[cnames]
}
parse_locations <- function(x) {
m <- regexec("([A-Z]{2,3})@([A-Z]{2,3})", x)
regs <- regmatches(x, m)
# replace empty vectors with NAs
regs[] <- lapply(regs, function(r) {
if (length(r) == 0) {
rep(NA_character_, 3)
} else {
r
}
})
# convert list to matrix
regs <- matrix(unlist(regs), ncol = 3, byrow = TRUE)
regs
}
#' Parse custom constraints
#' @param x a list of constraints. See examples
#' @keywords internal
#' @examples
#' \dontrun{
#' x <- list("QB" = 1, "RB" = 2, "WR" = 3, "TE" = 1, "RB/WR/TE" = 1, "DST" = 1)
#' parse_constraints(x)
#' }
parse_constraints <- function(x) {
# split flex positions (separated by a "/")
positions_split <- strsplit(names(x), "/")
positions_count <- vapply(positions_split, length, FUN.VALUE = integer(1L))
# unique positions
positions <- unique(unlist(positions_split))
# min number required for each position
min_count <- unlist(x[positions])
# max number allowed for each position
max_count <- lapply(seq_along(x), function(i) rep.int(x[[i]], positions_count[i]))
max_count <- tapply(unlist(max_count), unlist(positions_split), FUN = sum, simplify = FALSE)
max_count <- unlist(max_count[positions])
# combine into a data frame
data.frame(pos = positions, min = min_count, max = max_count,
stringsAsFactors = FALSE, row.names = NULL)
}
#' @rdname model_generic #Draftkings NFL Classic
#' @importFrom dplyr ROI ompr
#' @export
pff_model_dk_nfl <- function(data, existing_rosters = list()) {
# params
total_salary <- 50E3
roster_size <- 9L
max_from_team <- 4L
# build model
model_generic(data, total_salary, roster_size, max_from_team, existing_rosters) %>%
add_dk_nfl_roster_positions_constraint(data)
}
#' @importFrom ompr add_constraint sum_expr
#' @keywords internal
add_dk_nfl_roster_positions_constraint <- function(model, nfl) {
# position constraint helpers
n <- nrow(nfl)
is_position <- function(pos) {
function(i) {
as.integer(pos == nfl$position[i])
}
}
QB <- is_position("QB")
RB <- is_position("RB")
WR <- is_position("WR")
TE <- is_position("TE")
DST <- is_position("DST")
model %>%
# quater back
add_constraint(sum_expr(colwise(QB(i)) * x[i], i = 1:n) == 1) %>%
# running back
add_constraint(sum_expr(colwise(RB(i)) * x[i], i = 1:n) >= 2) %>%
add_constraint(sum_expr(colwise(RB(i)) * x[i], i = 1:n) <= 3) %>%
# wide receiver
add_constraint(sum_expr(colwise(WR(i)) * x[i], i = 1:n) >= 3) %>%
add_constraint(sum_expr(colwise(WR(i)) * x[i], i = 1:n) <= 4) %>%
# tight end
add_constraint(sum_expr(colwise(TE(i)) * x[i], i = 1:n) >= 1) %>%
add_constraint(sum_expr(colwise(TE(i)) * x[i], i = 1:n) <= 2) %>%
# defense
add_constraint(sum_expr(colwise(DST(i)) * x[i], i = 1:n) == 1)
}
setwd("D:/Dropbox/shiny_lineup_optimizer/opti/contests")
data <- read_dk("DKSalaries_NFL_CLASSIC_WEEK_ONE.csv")
optimize_generic(data, pff_model_dk_nfl(data), L = 10)
optimize_generic(data, pff_model_dk_nfl(data), L = 10, game_stack_sizes = 5)
optimize_generic(data, pff_model_dk_nfl(data), L = 10, stack_sizes = 4)
optimize_generic(data, pff_model_dk_nfl(data), L = 10, stack_sizes = 4, bans = c('420'))
optimize_generic(data, pff_model_dk_nfl(data), L = 10, stack_sizes = 4, bans = c(420, 203))
